{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESION LINEAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " K.ADNC´ÑSDCM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['loan_status'].value counts() #quitar current porque no se que va a apasar si vana a acabar pagando o no. coger fully paid y agrupar charged off y default para ver cuales no nos han pagado y cuales si reduciendo asi a la mitad nuestro dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df[loan_df[loan status] == fully paid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['zip_code'].head() # te das cuenta que esta capado por datos personales ddl cliente. te interesa saber el zipcode para saber que provincias tienen maypr poder adquisitivo para pagar las mortgages y cuales son mas risky\n",
    "#al estar capadas no puedo hacer nada por lo que quitamos esa columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*loan_df.isna().sum()/loan_df.shape(0)  #porcentaje na por columna para valores muy altos eliminamos la variable\n",
    "#para valores muy bajos lo cambias por la media y para valores medios pones un valor muy diferente al resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i:loan_df[i].nunique() for i in cat_features} #emp title tiene 125012 valores distintos Aportan valor? haces un loan_df[emp_title].value_counts()\n",
    "#igual director of manager es un manager y solo hay un director. para los que tngan menos de una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decidir que hago con los missing y que hago con las categorias cuando tengo tantas\n",
    "decididr como balancear el dataset ya que si esta en un 90% la pagan la prediccion te dira que siempre si la pagan y tendra un 90% de acierto. la cosa es que este balanceada para que te de buenas predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intertools import product\n",
    "import lightgbm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df filter loan status to fully paid y charged off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['loan_status'].value_counts(normalize = True)\n",
    "#vemos que estan un poco desbalanceados 70% fullyu paid y 30%charged off por lo tanto nuestro modelo no seria muy bueno al decirnos siempre que si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weight atributo scikit learn para balancear el modelo\n",
    "#random forest xgboos light gbm gradient boost tenemos este atributo\n",
    "#para los modelos que no tenemos este atributo tenemos que balancearlo nosotros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsample the minority class\n",
    "positive_df = loan_df[loan_df[loan_status]== 'fully paid']\n",
    "negative_df = loan_df[loan_df[loan_status]== 'charged off'].sample(n =negative_df .shape[0], random_state =42, replace = True)\n",
    "loan_df1 = pd.concat([positive_df,negative_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tambien se puede downsamplear\n",
    "# lo ideal es que en un submuestra hagamos el replace = True es decir coger un individuo y volverlo a meter en el saco para que pueda volver a ser elegido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = loan_df[loan_df[loan_status]== 'fully paid'].sample(n =10000, random_state =42, replace = True)\n",
    "negative_df = loan_df[loan_df[loan_status]== 'charged off'].sample(n =10000, random_state =42, replace = True)\n",
    "loan_df = pd.concat([positive_df,negative_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir al zoom a pillar cosas\n",
    "importante el remainder = passthrough al final del transformer para no eliminar las columnas que no esten metidas en el transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bde7087b1a9d2103f52211224a8eaca5bfa8026c2f495a791bcfbe564decae8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
